{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering Assignment\n",
        "\n",
        "### 1. What is a parameter?\n",
        "\n",
        "A parameter is an internal variable of a model that is learned from the training data. For example, in linear regression, the slope (weights) and intercept are parameters.\n",
        "\n",
        "\n",
        "### 2. What is correlation?\n",
        "\n",
        "Correlation measures the strength and direction of a linear relationship between two variables. It ranges from -1 to +1.\n",
        "\n",
        "\n",
        "* What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that as one variable increases, the other tends to decrease. A correlation value close to -1 indicates a strong negative relationship.\n",
        "\n",
        "\n",
        "### 3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine Learning (ML) is a field of AI that enables systems to learn patterns from data and make predictions.\n",
        "**Main components:**\n",
        "\n",
        "* Data\n",
        "* Model\n",
        "* Loss Function\n",
        "* Optimizer\n",
        "* Evaluation Metrics\n",
        "\n",
        "\n",
        "### 4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "The loss value quantifies the difference between the predicted and actual outputs. Lower loss indicates better model performance.\n",
        "\n",
        "\n",
        "### 5. What are continuous and categorical variables?\n",
        "\n",
        "* Continuous: Numeric variables with infinite possible values (e.g., age, salary).\n",
        "* Categorical: Discrete variables with limited categories (e.g., gender, color).\n",
        "\n",
        "\n",
        "### 6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "In Machine Learning, categorical variables are variables that contain label values rather than numeric values. Since most algorithms work only with numerical input, we must convert these categorical variables into a suitable numerical format. This process is known as encoding. There are several common techniques used to handle categorical variables:\n",
        "\n",
        "* Label Encoding - Converts categories to numbers.\n",
        "* One-Hot Encoding - Creates binary columns for each category.\n",
        "* Ordinal Encoding - For categories with order.\n",
        "\n",
        "\n",
        "### 7. What do you mean by training and testing a dataset?\n",
        "\n",
        "* Training: Data used to teach the model.\n",
        "* Testing: Data used to evaluate model performance on unseen data.\n",
        "\n",
        "\n",
        "### 8. What is sklearn.preprocessing?\n",
        "\n",
        "A module in Scikit-learn that provides functions for data preprocessing such as scaling, encoding, and normalization.\n",
        "\n",
        "\n",
        "### 9. What is a Test set?\n",
        "\n",
        "A test set is a subset of data used only for evaluating the performance of a trained machine learning model.\n",
        "\n",
        "\n",
        "### 10. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "Using `train_test_split()` from `sklearn.model_selection`:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "* How do you approach a Machine Learning problem?\n",
        "\n",
        "1. Understand the problem and data\n",
        "2. Perform Exploratory Data Analysis (EDA)\n",
        "3. Preprocess data\n",
        "4. Split into training/test sets\n",
        "5. Choose and train model\n",
        "6. Evaluate performance\n",
        "7. Tune hyperparameters\n",
        "8. Deploy the model\n",
        "\n",
        "\n",
        "### 11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "EDA helps:\n",
        "\n",
        "* Understand data distribution\n",
        "* Detect outliers and missing values\n",
        "* Discover relationships between variables\n",
        "* Guide feature engineering\n",
        "\n",
        "\n",
        "### 12. What is correlation? (repeated)\n",
        "\n",
        "See Answer #2 above.\n",
        "\n",
        "### 13. What does negative correlation mean? (repeated)\n",
        "\n",
        "See Answer #3 above.\n",
        "\n",
        "### 14. How can you find correlation between variables in Python?\n",
        "\n",
        "Using Pandas:\n",
        "\n",
        "```python\n",
        "df.corr()\n",
        "```\n",
        "\n",
        "### 15. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Causation means one variable directly affects another.\n",
        "Difference:\n",
        "\n",
        "* Correlation: Ice cream sales and drowning rates increase in summer.\n",
        "* Causation: Smoking causes lung cancer.\n",
        "\n",
        "\n",
        "### 16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "Optimizer updates model parameters to minimize loss.\n",
        "\n",
        "Types:\n",
        "\n",
        "* SGD (Stochastic Gradient Descent): Updates using a single sample.\n",
        "* Adam: Combines momentum and adaptive learning rates.\n",
        "* RMSprop: Adapts learning rate based on average of recent magnitudes of gradients.\n",
        "\n",
        "\n",
        "### 17. What is sklearn.linear\\_model?\n",
        "\n",
        "A Scikit-learn module that provides linear models like:\n",
        "\n",
        "* `LinearRegression()`\n",
        "* `LogisticRegression()`\n",
        "\n",
        "\n",
        "### 18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "It trains the model on data.\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "It predicts outcomes for new input data.\n",
        "\n",
        "```python\n",
        "predictions = model.predict(X_test)\n",
        "```\n",
        "\n",
        "### 20. What are continuous and categorical variables? (repeated)\n",
        "\n",
        "See Answer #6 above.\n",
        "\n",
        "### 21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling standardizes the range of features. It helps improve model convergence and performance.\n",
        "\n",
        "### 22. How do we perform scaling in Python?\n",
        "\n",
        "Using Scikit-learn:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "### 23. What is sklearn.preprocessing? (repeated)\n",
        "\n",
        "See Answer #9 above.\n",
        "\n",
        "\n",
        "### 24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "To evaluate a machine learning model fairly, the dataset is typically split into two or more parts: **training** and **testing** sets. The training set is used to teach the model, while the testing set evaluates how well the model performs on unseen data.\n",
        "\n",
        "In Python, the most common method to do this is using train_test_split() from sklearn.model_selection\n",
        "\n",
        "#### Code Example:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X is the feature matrix, y is the target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "\n",
        "* test_size=0.2 means 20% of the data will be used for testing.\n",
        "* random_state ensures reproducibility of the split.\n",
        "* This results in four datasets: X_train, X_test, y_train, y_test.\n",
        "\n",
        "\n",
        "### 25. Explain Data Encoding\n",
        "\n",
        "Data encoding is the process of converting categorical (non-numeric) data into a numeric format that can be used by machine learning algorithms, which generally require numerical input.\n",
        "\n",
        "There are several common encoding techniques:\n",
        "\n",
        "#### 1. Label Encoding\n",
        "\n",
        "* Assigns a unique integer to each category.\n",
        "* Useful for ordinal data (e.g., \"Low\" = 0, \"Medium\" = 1, \"High\" = 2).\n",
        "* Not ideal for nominal data due to potential misinterpretation of order.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Category'] = le.fit_transform(df['Category'])\n",
        "```\n",
        "\n",
        "#### 2. One-Hot Encoding\n",
        "\n",
        "* Creates a new binary column for each category.\n",
        "* Best suited for nominal (unordered) categories.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.get_dummies(df, columns=['Category'])\n",
        "```\n",
        "\n",
        "#### 3. Ordinal Encoding\n",
        "\n",
        "* Similar to label encoding but specifically for ordered categories.\n",
        "* Explicit order can be defined during encoding.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
        "df[['Level']] = encoder.fit_transform(df[['Level']])\n",
        "```\n",
        "\n",
        "#### 4. Target Encoding (advanced)\n",
        "\n",
        "* Replaces each category with the average target value for that category.\n",
        "* Can overfit; often used with regularization or cross-validation.\n",
        "\n",
        "\n",
        "Encoding ensures that the model interprets categorical variables correctly, improving training efficiency and accuracy. Choosing the right encoding method depends on whether the categories are ordinal or nominal and on the type of machine learning algorithm used.\n"
      ],
      "metadata": {
        "id": "t8vT1b3QXSJG"
      }
    }
  ]
}